{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "39eaf61b",
            "metadata": {},
            "source": [
                "# Изменение параметров в процессе выполнения\n",
                "\n",
                ":::note\n",
                "\n",
                "С этим руководством будет проще работать, если ознакомиться с разделами:\n",
                "\n",
                "- [LangChain Expression Language (LCEL)](/docs/concepts/#langchain-expression-language)\n",
                "- [Chaining runnables](/docs/how_to/sequence/)\n",
                "- [Binding runtime arguments](/docs/how_to/binding/)\n",
                "\n",
                ":::\n",
                "\n",
                "В процессе работы вы можете захотеть проверить разные гипотезы или показать конечному пользователю различные способы использования ваших цепочек.\n",
                "Для этого может понадобиться изменить какой-нибудь параметр, например температуру, или заменить одну модель на другую.\n",
                "\n",
                "Для таких ситуаций в LCEL есть два метода, которые позволяют изменять параметры цепочки в процессе выполнения:\n",
                "\n",
                "* `configurable_fields` — позволяет задавать определенные поля Runnable-объектов;\n",
                "\n",
                "  Работа с этим методом связанна с использованием метода Runnable-объектов [`.bind`](/docs/how_to/binding). Но в отличие от последнего метод `configurable_fields` позволяет задавать параметры на определенном шаге работы цепочки, а не перед ее запуском.\n",
                "\n",
                "* `configurable_alternatives` — позволяет в процессе выполнения задать список альтернативных значений параметров для определенного Runnable-объекта, которые можно менять в процессе работы цепочки."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f2347a11",
            "metadata": {},
            "source": [
                "## Изменение определенных полей"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a06f6e2d",
            "metadata": {},
            "source": [
                "### Языковые модели\n",
                "\n",
                "Для языковых моделей можно изменять такие параметры, как температура."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "40ed76a2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
                        "You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
                        "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "%pip install --upgrade --quiet gigachain gigachain-openai\n",
                "\n",
                "import os\n",
                "from getpass import getpass\n",
                "\n",
                "os.environ[\"OPENAI_API_KEY\"] = getpass()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "7ba735f4",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content='17', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 11, 'total_tokens': 12}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-ba26a0da-0a69-4533-ab7f-21178a73d303-0')"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain.prompts import PromptTemplate\n",
                "from langchain_core.runnables import ConfigurableField\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "model = ChatOpenAI(temperature=0).configurable_fields(\n",
                "    temperature=ConfigurableField(\n",
                "        id=\"llm_temperature\",\n",
                "        name=\"LLM Temperature\",\n",
                "        description=\"The temperature of the LLM\",\n",
                "    )\n",
                ")\n",
                "\n",
                "model.invoke(\"pick a random number\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b0f74589",
            "metadata": {},
            "source": [
                "В примере выше параметр `temperature` задан с промощью [`ConfigurableField`](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField), что позволяет менять его в процессе работы.\n",
                "Используем для этого метод [`with_config`](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_config):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "4f83245c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content='12', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 11, 'total_tokens': 12}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-ba8422ad-be77-4cb1-ac45-ad0aae74e3d9-0')"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model.with_config(configurable={\"llm_temperature\": 0.9}).invoke(\"pick a random number\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9da1fcd2",
            "metadata": {},
            "source": [
                "Обратите внимание, что переданный параметр `llm_temperature` совпадает со значением поля `id` заданного при вызове `ConfigurableField`.\n",
                "\n",
                "Изменять параметры можно и в рамках цепочки."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "e75ae678",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content='27', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 14, 'total_tokens': 15}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-ecd4cadd-1b72-4f92-b9a0-15e08091f537-0')"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "prompt = PromptTemplate.from_template(\"Pick a random number above {x}\")\n",
                "chain = prompt | model\n",
                "\n",
                "chain.invoke({\"x\": 0})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "c09fac15",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content='35', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 14, 'total_tokens': 15}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-a916602b-3460-46d3-a4a8-7c926ec747c0-0')"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "chain.with_config(configurable={\"llm_temperature\": 0.9}).invoke({\"x\": 0})"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fb9637d0",
            "metadata": {},
            "source": [
                "### Экземпляры HubRunnables\n",
                "\n",
                "Экземпляры HubRunnables используются, если нужно заменить промпт."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "9a9ea077",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "ChatPromptValue(messages=[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: foo \\nContext: bar \\nAnswer:\")])"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain.runnables.hub import HubRunnable\n",
                "\n",
                "prompt = HubRunnable(\"rlm/rag-prompt\").configurable_fields(\n",
                "    owner_repo_commit=ConfigurableField(\n",
                "        id=\"hub_commit\",\n",
                "        name=\"Hub Commit\",\n",
                "        description=\"The Hub commit to pull from\",\n",
                "    )\n",
                ")\n",
                "\n",
                "prompt.invoke({\"question\": \"foo\", \"context\": \"bar\"})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "f33f3cf2",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "ChatPromptValue(messages=[HumanMessage(content=\"[INST]<<SYS>> You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.<</SYS>> \\nQuestion: foo \\nContext: bar \\nAnswer: [/INST]\")])"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "prompt.with_config(configurable={\"hub_commit\": \"rlm/rag-prompt-llama\"}).invoke(\n",
                "    {\"question\": \"foo\", \"context\": \"bar\"}\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "79d51519",
            "metadata": {},
            "source": [
                "## Настройка альтернативных значений\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ac733d35",
            "metadata": {},
            "source": [
                "### Для языковых моделей\n",
                "\n",
                "С помощью метода `configurable_alternatives()` вы можете менять шаги выполнения цепочки на заданные альтернативные значения. \n",
                "Пример демонстрирует замену языковых моделей."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "3db59f45",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
                        "You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
                        "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "%pip install --upgrade --quiet langchain-anthropic\n",
                "\n",
                "import os\n",
                "from getpass import getpass\n",
                "\n",
                "os.environ[\"ANTHROPIC_API_KEY\"] = getpass()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "71248a9f",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\"Here's a bear joke for you:\\n\\nWhy don't bears wear socks? \\nBecause they have bear feet!\\n\\nHow's that? I tried to come up with a simple, silly pun-based joke about bears. Puns and wordplay are a common way to create humorous bear jokes. Let me know if you'd like to hear another one!\", response_metadata={'id': 'msg_018edUHh5fUbWdiimhrC3dZD', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 13, 'output_tokens': 80}}, id='run-775bc58c-28d7-4e6b-a268-48fa6661f02f-0')"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain_anthropic import ChatAnthropic\n",
                "\n",
                "llm = ChatAnthropic(temperature=0).configurable_alternatives(\n",
                "    # Задает id поля.\n",
                "    # id можно использовать для изменения поля при созданиии итогового экземпляра Runnable\n",
                "    ConfigurableField(id=\"llm\"),\n",
                "    # Поле `default_key` содержит информцию о модели, которая используется по умолчанию (ChatAnthropic)\n",
                "    default_key=\"anthropic\",\n",
                "    # Поле `openai` задает возможность использовать `ChatOpenAI()`\n",
                "    openai=ChatOpenAI(),\n",
                "    # Поле `gpt4` задает возможность использовать `ChatOpenAI(model=\"gpt-4\")`\n",
                "    gpt4=ChatOpenAI(model=\"gpt-4\"),\n",
                "    # Вы можете добавить другие варианты.\n",
                ")\n",
                "prompt = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
                "chain = prompt | llm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "e598b1f1",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\" Here's a silly joke about bears:\\n\\nWhat do you call a bear with no teeth?\\nA gummy bear!\")"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# По умолчанию используется модель Anthropic\n",
                "chain.invoke({\"topic\": \"bears\"})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "48b45337",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\"Why don't bears like fast food?\\n\\nBecause they can't catch it!\", response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 13, 'total_tokens': 28}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-7bdaa992-19c9-4f0d-9a0c-1f326bc992d4-0')"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Используйте `.with_config(configurable={\"llm\": \"openai\"})`, чтобы задать модель\n",
                "chain.with_config(configurable={\"llm\": \"openai\"}).invoke({\"topic\": \"bears\"})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "42647fb7",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\"Here's a bear joke for you:\\n\\nWhy don't bears wear socks? \\nBecause they have bear feet!\\n\\nHow's that? I tried to come up with a simple, silly pun-based joke about bears. Puns and wordplay are a common way to create humorous bear jokes. Let me know if you'd like to hear another one!\", response_metadata={'id': 'msg_01BZvbmnEPGBtcxRWETCHkct', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 13, 'output_tokens': 80}}, id='run-59b6ee44-a1cd-41b8-a026-28ee67cdd718-0')"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Или передайте значение поля `default_key` чтобы импользовать модель, заданную по умолчанию\n",
                "chain.with_config(configurable={\"llm\": \"anthropic\"}).invoke({\"topic\": \"bears\"})"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a9134559",
            "metadata": {},
            "source": [
                "### Для промптов\n",
                "\n",
                "Вы также можете задавать альтернативные промпты.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "9f6a7c6c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\"Here's a bear joke for you:\\n\\nWhy don't bears wear socks? \\nBecause they have bear feet!\", response_metadata={'id': 'msg_01DtM1cssjNFZYgeS3gMZ49H', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 13, 'output_tokens': 28}}, id='run-8199af7d-ea31-443d-b064-483693f2e0a1-0')"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0)\n",
                "prompt = PromptTemplate.from_template(\n",
                "    \"Tell me a joke about {topic}\"\n",
                ").configurable_alternatives(\n",
                "    # Задает id поля\n",
                "    # id можно использовать для изменения поля при созданиии итогового экземпляра Runnable\n",
                "    ConfigurableField(id=\"prompt\"),\n",
                "    # Поле `default_key` указывает, что по умолчанию будет генерироваться шутка.\n",
                "    default_key=\"joke\",\n",
                "    # Поле `poem` задает возможность сгенерироват стих.\n",
                "    poem=PromptTemplate.from_template(\"Write a short poem about {topic}\"),\n",
                "    # Вы можете добавить другие варианты.\n",
                ")\n",
                "chain = prompt | llm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "97eda915",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\" Here's a silly joke about bears:\\n\\nWhat do you call a bear with no teeth?\\nA gummy bear!\")"
                        ]
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# По умолчанию генерируется шутка\n",
                "chain.invoke({\"topic\": \"bears\"})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "927297a1",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\"Here is a short poem about bears:\\n\\nMajestic bears, strong and true,\\nRoaming the forests, wild and free.\\nPowerful paws, fur soft and brown,\\nCommanding respect, nature's crown.\\n\\nForaging for berries, fishing streams,\\nProtecting their young, fierce and keen.\\nMighty bears, a sight to behold,\\nGuardians of the wilderness, untold.\\n\\nIn the wild they reign supreme,\\nEmbodying nature's grand theme.\\nBears, a symbol of strength and grace,\\nCaptivating all who see their face.\", response_metadata={'id': 'msg_01Wck3qPxrjURtutvtodaJFn', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 13, 'output_tokens': 134}}, id='run-69414a1e-51d7-4bec-a307-b34b7d61025e-0')"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Передайте значение `poem`, чтобы сгенерировать стих\n",
                "chain.with_config(configurable={\"prompt\": \"poem\"}).invoke({\"topic\": \"bears\"})"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0c77124e",
            "metadata": {},
            "source": [
                "### Для промптов и моделей\n",
                "\n",
                "Параметры промптов и моделей можно задавать одновременно."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "97538c23",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\"In the forest deep and wide,\\nBears roam with grace and pride.\\nWith fur as dark as night,\\nThey rule the land with all their might.\\n\\nIn winter's chill, they hibernate,\\nIn spring they emerge, hungry and great.\\nWith claws sharp and eyes so keen,\\nThey hunt for food, fierce and lean.\\n\\nBut beneath their tough exterior,\\nLies a gentle heart, warm and superior.\\nThey love their cubs with all their might,\\nProtecting them through day and night.\\n\\nSo let us admire these majestic creatures,\\nIn awe of their strength and features.\\nFor in the wild, they reign supreme,\\nThe mighty bears, a timeless dream.\", response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 13, 'total_tokens': 146}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-5eec0b96-d580-49fd-ac4e-e32a0803b49b-0')"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "llm = ChatAnthropic(temperature=0).configurable_alternatives(\n",
                "    # Задает id поля.\n",
                "    # id можно использовать для изменения поля при созданиии итогового экземпляра Runnable\n",
                "    ConfigurableField(id=\"llm\"),\n",
                "    # Поле `default_key` содержит информцию о модели, которая используется по умолчанию (ChatAnthropic)\n",
                "    default_key=\"anthropic\",\n",
                "    # Поле `openai` задает возможность использовать `ChatOpenAI()`\n",
                "    openai=ChatOpenAI(),\n",
                "    # Поле `gpt4` задает возможность использовать `ChatOpenAI(model=\"gpt-4\")`\n",
                "    gpt4=ChatOpenAI(model=\"gpt-4\"),\n",
                "    # Вы можете добавить другие варианты.\n",
                ")\n",
                "prompt = PromptTemplate.from_template(\n",
                "    \"Tell me a joke about {topic}\"\n",
                ").configurable_alternatives(\n",
                "    # Задает id поля\n",
                "    # id можно использовать для изменения поля при созданиии итогового экземпляра Runnable\n",
                "    ConfigurableField(id=\"prompt\"),\n",
                "    # Поле `default_key` указывает, что по умолчанию будет генерироваться шутка.\n",
                "    default_key=\"joke\",\n",
                "    # Поле `poem` задает возможность сгенерироват стих.\n",
                "    poem=PromptTemplate.from_template(\"Write a short poem about {topic}\"),\n",
                "    # Вы можете добавить другие варианты.\n",
                ")\n",
                "chain = prompt | llm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "1dcc7ccc",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\"In the forest, where tall trees sway,\\nA creature roams, both fierce and gray.\\nWith mighty paws and piercing eyes,\\nThe bear, a symbol of strength, defies.\\n\\nThrough snow-kissed mountains, it does roam,\\nA guardian of its woodland home.\\nWith fur so thick, a shield of might,\\nIt braves the coldest winter night.\\n\\nA gentle giant, yet wild and free,\\nThe bear commands respect, you see.\\nWith every step, it leaves a trace,\\nOf untamed power and ancient grace.\\n\\nFrom honeyed feast to salmon's leap,\\nIt takes its place, in nature's keep.\\nA symbol of untamed delight,\\nThe bear, a wonder, day and night.\\n\\nSo let us honor this noble beast,\\nIn forests where its soul finds peace.\\nFor in its presence, we come to know,\\nThe untamed spirit that in us also flows.\")"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Итоговая цепочка вернет стих, сгенерированный с помощью OpenAI\n",
                "chain.with_config(configurable={\"prompt\": \"poem\", \"llm\": \"openai\"}).invoke(\n",
                "    {\"topic\": \"bears\"}\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "e4ee9fbc",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\"Why don't bears wear shoes?\\n\\nBecause they have bear feet!\", response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 13, 'total_tokens': 26}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-c1b14c9c-4988-49b8-9363-15bfd479973a-0')"
                        ]
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# We can always just configure only one if we want\n",
                "chain.with_config(configurable={\"llm\": \"openai\"}).invoke({\"topic\": \"bears\"})"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "02fc4841",
            "metadata": {},
            "source": [
                "### Сохранение конфигураций\n",
                "\n",
                "Настроенные цепочки можно сохранять как отдельные объекты."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "5cf53202",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\"Why did the bear break up with his girlfriend? \\nBecause he couldn't bear the relationship anymore!\", response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 13, 'total_tokens': 33}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-391ebd55-9137-458b-9a11-97acaff6a892-0')"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "openai_joke = chain.with_config(configurable={\"llm\": \"openai\"})\n",
                "\n",
                "openai_joke.invoke({\"topic\": \"bears\"})"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "94450f71",
            "metadata": {},
            "source": [
                "## Смотрите также\n",
                "\n",
                "- [Привязка аргументов](/docs/how_to/binding)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}