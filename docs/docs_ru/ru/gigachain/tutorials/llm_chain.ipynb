{
 "cells": [
  {
   "cell_type": "raw",
   "id": "63ee3f93",
   "metadata": {
    "id": "63ee3f93"
   },
   "source": [
    "---\n",
    "sidebar_position: 0\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9316da0d",
   "metadata": {
    "id": "9316da0d"
   },
   "source": [
    "# Разработка простого LLM-приложения\n",
    "\n",
    "В этом разделе показан пример разработки LLM-приложения, которое переводит текст с английского языка на другой язык.\n",
    "Итоговое приложение включает всего один вызов LLM плюс некоторую работу с промптами.\n",
    "Это довольно простое приложение, но оно показывает, что множество функций можно реализовать только с помощью промптов и вызова LLM.\n",
    "\n",
    "## Основные понятия\n",
    "\n",
    "В разделе рассмотрены следующие основные понятия:\n",
    "\n",
    "- использование [языковых моделей](/docs/concepts/#chat-models);\n",
    "- использование [шаблонов промптов](/docs/concepts/#prompt-templates) и [парсеров вывода](/docs/concepts/#output-parsers);\n",
    "- [объединение в цепочку](/docs/concepts/#langchain-expression-language) шаблона промптов + LLM + парсера вывода с помощью GigaChain\n",
    "\n",
    "- Развертывание вашего приложения с [LangServe](/docs/concepts/#langserve).\n",
    "<!--\n",
    "- Отладка и трассировка вашего приложения с помощью [LangSmith](/docs/concepts/#langsmith)\n",
    "-->\n",
    "\n",
    "## Подготовка к разработке\n",
    "\n",
    "### Jupyter-блокноты\n",
    "\n",
    "Это руководство, как и большинство других в документации, использует [Jupyter-блокноты](https://jupyter.org/). Они отлично подходят для изучения работы с LLM-системами, так как предоставляют интерактивную среду для работы с руководствами и позволяют работать с непредвиденными ситуациями: недоступностью API, нетипичным выводом и другими.\n",
    "\n",
    "Подробнее об установке jupyter — в [официальной документации](https://jupyter.org/install).\n",
    "\n",
    "### Установка\n",
    "\n",
    "Для установки GigaChain выполните команду:\n",
    "\n",
    "<!--\n",
    "### LangSmith\n",
    "\n",
    "Многие приложения, которые вы создаете с помощью LangChain, будут содержать несколько шагов с многократными вызовами LLM.\n",
    "По мере усложнения этих приложений становится важно иметь возможность инспектировать, что именно происходит внутри вашей цепочки или агента.\n",
    "Лучший способ сделать это — с помощью [LangSmith](https://smith.langchain.com).\n",
    "\n",
    "После регистрации по ссылке выше, убедитесь, что вы установили переменные среды для начала ведения журнала трассировок:\n",
    "\n",
    "```shell\n",
    "export LANGCHAIN_TRACING_V2=\"true\"\n",
    "export LANGCHAIN_API_KEY=\"...\"\n",
    "```\n",
    "\n",
    "Или, если вы работаете в блокноте, вы можете установить их с помощью:\n",
    "\n",
    "```python\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "```\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FwNM8IST3y7E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwNM8IST3y7E",
    "outputId": "c0d17d7c-8e7d-4258-dc43-c38bb1991766"
   },
   "outputs": [],
   "source": [
    "pip install gigachain gigachain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b7a2a",
   "metadata": {},
   "source": [
    "Подробнее об установке — в разделе [Установка](https://developers.sber.ru/docs/ru/gigachain/get-started/installation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5558ca9",
   "metadata": {
    "id": "e5558ca9"
   },
   "source": [
    "## Работа с языковыми моделями\n",
    "\n",
    "В первую очередь для работы использования GigaChain нужно подключить языковую модель.\n",
    "\n",
    "Хотя GigaChain поддерживает различные языковые модели, основным преимуществом библиотеки является возможность работы с моделями GigaChat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4b41234",
   "metadata": {
    "id": "e4b41234"
   },
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "\n",
    "model = GigaChat(\n",
    "    credentials=\"<авторизационные_данные>\",\n",
    "    scope=\"GIGACHAT_API_PERS\",\n",
    "    model=\"GigaChat\",\n",
    "    verify_ssl_certs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5642ff",
   "metadata": {
    "id": "ca5642ff"
   },
   "source": [
    ":::note\n",
    "\n",
    "Объект GigaChat принимает параметры:\n",
    "\n",
    "- `credentials` — авторизационные данные для обмена сообщениями с GigaChat API. О том как получить атворизационные данные — в разделе [Быстрый старт](/ru/gigachat/individuals-quickstart).\n",
    "- `scope` — необязательный параметр, в котором можно указать версию API, к которой нужно обратиться. Возможные значения:\n",
    "  \n",
    "  - `GIGACHAT_API_PERS` — версия API для физических лиц;\n",
    "  - `GIGACHAT_API_CORP` — версия API для ИП и юрлиц.\n",
    "\n",
    "  По умолчанию запросы передаются в версию для физических лиц.\n",
    "\n",
    "- `model` — необязательный параметр, в котором можно явно задать [модель GigaChat](/ru/gigachat/models).\n",
    "- `verify_ssl_certs` — необязательный параметр, с помощью которого можно отключить проверку [сертификатов НУЦ Минцифры](/ru/gigachat/certificates).\n",
    "\n",
    ":::\n",
    "\n",
    "Попробуйте обратиться к модели напрямую.\n",
    "\n",
    "Объекты `ChatModel` — это экземпляры Runnable-интерфейса GigaChain.\n",
    "Все экземпляры Runnable предоставляют стандартный интерфейс для взаимподействия.\n",
    "\n",
    "Так, чтобы обратиться к модели достаточно вызвать метод `.invoke()` со списком сообщений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b2481f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b2481f0",
    "outputId": "56e9f494-3fa5-488f-a3fe-df8993b755b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello!', response_metadata={'token_usage': Usage(prompt_tokens=22, completion_tokens=3, total_tokens=25), 'model_name': 'GigaChat:3.1.25.3', 'finish_reason': 'stop'}, id='run-61e07c28-4b05-469c-97be-472b0f4e990f-0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Переведи следующее сообщение с русского на английский\"),\n",
    "    HumanMessage(content=\"привет!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83373db",
   "metadata": {
    "id": "f83373db"
   },
   "source": [
    "<!--\n",
    "Если мы включили LangSmith, мы можем увидеть, что этот запуск зарегистрирован в LangSmith, и просмотреть [трассировку LangSmith](https://smith.langchain.com/public/88baa0b2-7c1a-4d09-ba30-a47985dde2ea/r).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd03ed",
   "metadata": {
    "id": "32bd03ed"
   },
   "source": [
    "## Парсеры вывода OutputParsers\n",
    "\n",
    "Ответ модели возвращается в форме сообщения `AIMessage`.\n",
    "Он содержит сгенерированный текст и дополнительную информацию, например, количество затраченных токенов.\n",
    "Зачастую для работы достаточно сгенерированного текста.\n",
    "Чтобы получить его отдельно вы можете использовать парсер вывода.\n",
    "\n",
    "Импортируйте простой парсер вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ae9c58",
   "metadata": {
    "id": "d7ae9c58"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaebe33a",
   "metadata": {
    "id": "eaebe33a"
   },
   "source": [
    "Парсер можно использовать отдельно.\n",
    "Например, вы можете сохранить результат вызова модели и затем передать его в парсер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bacb837",
   "metadata": {
    "id": "6bacb837"
   },
   "outputs": [],
   "source": [
    "result = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb8da87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "efb8da87",
    "outputId": "db1d245b-bfc0-412f-c998-20877e8b203c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d508b79d",
   "metadata": {
    "id": "d508b79d"
   },
   "source": [
    "Но чаще вам будет нужно соединять в цепочку парсер вывода и модель.\n",
    "В таких случаях парсер вызывается каждый раз при обращении к цепочке.\n",
    "Итоговая цепочка будет принимать на вход тип данных модели (строку или список сообщений) и возвращать тип данных парсера вывода (строка).\n",
    "\n",
    "Вы можете создать цепочку с помощью оператора `|`, который используется в GigaChain для собъединения двух и более компонетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9449cfa6",
   "metadata": {
    "id": "9449cfa6"
   },
   "outputs": [],
   "source": [
    "chain = model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e82f933",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3e82f933",
    "outputId": "85129324-c7ee-4586-f298-10740640bc1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd009096",
   "metadata": {
    "id": "dd009096"
   },
   "source": [
    "<!--\n",
    "Если мы теперь посмотрим на LangSmith, мы увидим, что цепочка состоит из двух шагов: сначала вызывается языковая модель, затем результат передается парсеру вывода. Мы можем увидеть [трассировку LangSmith](https://smith.langchain.com/public/f1bdf656-2739-42f7-ac7f-0f1dd712322f/r).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab8da31",
   "metadata": {
    "id": "1ab8da31"
   },
   "source": [
    "## Шаблоны промптов\n",
    "\n",
    "Сейчас список сообщений в примере передается напрямую в модель.\n",
    "Сам список сообщений, как правило, формируется логикой приложения из ввода пользователя.\n",
    "Обычно такая логика принимает необработанный ввод и преобразует его в список сообщений, готовых для передачи в языковую модель.\n",
    "Типичные преобразования включают добавление системного сообщения или изменение шаблона с учетом ввода пользователя.\n",
    "\n",
    "Шаблоны промптов (PromptTemplates) — это конструкции GigaChain, которые принимают необработанный ввод пользователя и возвращают данные (промпт), готовые для передачи в языковую модель.\n",
    "\n",
    "Создайте шаблон промпта, который будет принимать две пользовательские переменные:\n",
    "\n",
    "- `language` — язык, на который нужно перевести текст;\n",
    "- `text` — текст для перевода.\n",
    "\n",
    "Для этого импортируйте `ChatPromptTemplate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e73cc20",
   "metadata": {
    "id": "3e73cc20"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e876c2a",
   "metadata": {
    "id": "7e876c2a"
   },
   "source": [
    "Создайте строку, которая будет оформлена как системное сообщение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd75ecde",
   "metadata": {
    "id": "fd75ecde"
   },
   "outputs": [],
   "source": [
    "system_template = \"Переведи следующий текст на {language}:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf6f13",
   "metadata": {
    "id": "fedf6f13"
   },
   "source": [
    "Теперь вы можете создать шаблон промпта.\n",
    "Он будет состоять из комбинации `system_template` и шаблона для ввода текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88e566f3",
   "metadata": {
    "id": "88e566f3"
   },
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9711ba6",
   "metadata": {
    "id": "d9711ba6"
   },
   "source": [
    "Входными данными для этого шаблона является словарь.\n",
    "Вы можем поэкспериментировать с этим шаблоном, чтобы увидеть, что он делает сам по себе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f781b3cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f781b3cb",
    "outputId": "03287299-217b-4e2f-c402-8b91133c2f6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Переведи следующий текст на английский:'), HumanMessage(content='привет')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt_template.invoke({\"language\": \"английский\", \"text\": \"привет\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49ba9e",
   "metadata": {
    "id": "1a49ba9e"
   },
   "source": [
    "Шаблон возвращает объект `ChatPromptValue`, который состоит из двух сообщений.\n",
    "Доступ к сообщениям можно получить с помощью метода `.to_messages()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2159b619",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2159b619",
    "outputId": "9a576eda-1c93-4cfb-c49b-635f943ec384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Переведи следующий текст на английский:'),\n",
       " HumanMessage(content='привет')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4267a8",
   "metadata": {
    "id": "5a4267a8"
   },
   "source": [
    "## Соединение всех компонентов вместе\n",
    "\n",
    "Теперь объедините все три компонента вместе: шаблон, модель и парсер вывода с помощью оператора `|`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c6beb4b",
   "metadata": {
    "id": "6c6beb4b"
   },
   "outputs": [],
   "source": [
    "chain = prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e45595a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3e45595a",
    "outputId": "6877f272-e3fa-43e4-c158-099793be1ca6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"английский\", \"text\": \"привет\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b19cecb",
   "metadata": {
    "id": "0b19cecb"
   },
   "source": [
    "Это простой пример использования [LangChain Expression Language (LCEL)](/docs/concepts/#langchain-expression-language-lcel) для соединения вместе модулей GigaChain.\n",
    "В таком подходе есть ряд преимуществ. В частности, он обеспечивает оптимизированную работу с потоковой передачей.\n",
    "\n",
    "<!--\n",
    "Если мы посмотрим на трассировку LangSmith, мы увидим все три компонента в [трассировке LangSmith](https://smith.langchain.com/public/bc49bec0-6b13-4726-967f-dbd3448b786d/r).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a927eb",
   "metadata": {},
   "source": [
    "## Развертывание с GigaServe\n",
    "\n",
    "GigaServe помогает развертывать цепочки GigaChain в виде REST API.\n",
    "Использовать GigaServe для работы с GigaChain необязательно.\n",
    "Тем не менее ниже приводится пример, как вы можете развернуть приложение с помощью GigaServe.\n",
    "\n",
    "Пример использует Python-файл, работа с которым выполняется с помощью командной строки.\n",
    "\n",
    "Установка GigaServe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"gigaserve[all]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a515ddd0",
   "metadata": {
    "id": "a515ddd0"
   },
   "source": [
    "### Сервер\n",
    "\n",
    "Для создания сервера для приложения, создайте файл `serve.py`.\n",
    "Файл будет содержать логику для развертывания приложения.\n",
    "Файл состоит из трех частей:\n",
    "\n",
    "1. Определение цепочки, которую вы создали выше.\n",
    "2. Приложение FastAPI.\n",
    "3. Определение пути для доступа к цепочки с помощью `langserve.add_routes`.\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "from typing import List\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "from langserve import add_routes\n",
    "\n",
    "# 1. Создание шаблона промпта\n",
    "system_template = \"Переведи следующий текст на {language}:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "# 2. Создание модели\n",
    "model = GigaChat(credentials=\"MmY5ZjI0YTgtOTQ5My00MzZjLWI0NDQtZDdiMTc3NTY5MGI4OmQ4MTY2NjViLWRjYzEtNGZhOC1hNzBiLWNkMDM5NWY2NjIzNQ==\", scope=\"GIGACHAT_API_CORP\", model=\"GigaChat-Pro\", verify_ssl_certs=False)\n",
    "\n",
    "# 3. Создание парсера\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 4. Создание цепочки\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "# 4. Определение приложения\n",
    "app = FastAPI(\n",
    "  title=\"GigaChain Server\",\n",
    "  version=\"1.0\",\n",
    "  description=\"Простой сервер API, использующий Runnable-интерфейсы GigaChain.\",\n",
    ")\n",
    "\n",
    "# 5. Добавление пути цепочки\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    chain,\n",
    "    path=\"/chain\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)\n",
    "```\n",
    "\n",
    "Запустите файл:\n",
    "```bash\n",
    "python serve.py\n",
    "```\n",
    "Вы должны увидеть, что ваша цепочка доступна по адресу [http://localhost:8000](http://localhost:8000).\n",
    "\n",
    "### Песочница\n",
    "\n",
    "Приложения GigaServe предоставляют доступ к простому [пользовательскому интерфейсу](https://github.com/langchain-ai/langserve/blob/main/README.md#playground) для настройки и вызова приложения с потоковым выводом и отображением промежуточных шагов.\n",
    "Вы можете попробовать его по адресу [http://localhost:8000/chain/playground/](http://localhost:8000/chain/playground/).\n",
    "Задай такие же входные данные — `{\"language\": \"английский\", \"text\": \"привет\"}` — приложение должно ответить как и раньше.\n",
    "\n",
    "### Клиент\n",
    "\n",
    "Для настройки клиентской части используйте [`langserve.RemoteRunnable`](/docs/langserve/#client).\n",
    "Так вы сможете взаимодействовать с доступной цепочкой так, как если бы она выполнялась на стороне клиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85174643",
   "metadata": {
    "id": "85174643"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/chain/\")\n",
    "remote_chain.invoke({\"language\": \"английский\", \"text\": \"привет\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b78a9",
   "metadata": {
    "id": "480b78a9"
   },
   "source": [
    "Подробнее — в [документации GigaServe](/docs/langserve)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befdb168",
   "metadata": {
    "id": "befdb168"
   },
   "source": [
    "## Смотрите также\n",
    "\n",
    "Чтобы глубже погрузиться в разработку приложений с помощью GigaChain, ознакомьтесь с разделами:\n",
    "\n",
    "- [Обучающие материалы](/docs/tutorials);\n",
    "- [Руководства](/docs/how_to);\n",
    "- [Основные понятия](/docs/concepts)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
