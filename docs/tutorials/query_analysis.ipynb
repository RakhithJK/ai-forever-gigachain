{
    "cells": [
        {
            "cell_type": "raw",
            "id": "df7d42b9-58a6-434c-a2d7-0b61142f6d3e",
            "metadata": {},
            "source": [
                "---\n",
                "sidebar_position: 0\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f2195672-0cab-4967-ba8a-c6544635547d",
            "metadata": {},
            "source": [
                "# Создание системы анализа запросов\n",
                "\n",
                "Раздел содержит готовый пример, который показывает, как использовать анализ запросов.\n",
                "Пример демонстрирует:\n",
                "\n",
                "- создание простого поискового движка;\n",
                "- режим ошибки, который возникает при передаче необработанного вопроса пользователя в поиск;\n",
                "- как анализ запросов может помочь исправить возникшую ошибку. \n",
                "\n",
                ":::note\n",
                "\n",
                "Существует множество разных методик анализа запросов, которые не показаны в примере.\n",
                "\n",
                ":::\n",
                "\n",
                "Анализ запросов продемонстрирован на примере поиска по видео на YouTube-канале LangChain."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a4079b57-4369-49c9-b2ad-c809b5408d7e",
            "metadata": {},
            "source": [
                "## Подготовка к работе\n",
                "\n",
                "Установите зависимости и переменные окружения."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "e168ef5c-e54e-49a6-8552-5502854a6f01",
            "metadata": {},
            "outputs": [],
            "source": [
                "# %pip install -qU langchain langchain-community langchain-openai youtube-transcript-api pytube gigachain-chroma"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "79d66a45-a05c-4d22-b011-b1cdbdfc8f9c",
            "metadata": {},
            "source": [
                "При работе с этим руководством используется модель OpenAI."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "40e2979e-a818-4b96-ac25-039336f94319",
            "metadata": {},
            "outputs": [],
            "source": [
                "import getpass\n",
                "import os\n",
                "\n",
                "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
                "\n",
                "# Optional, uncomment to trace runs with LangSmith. Sign up here: https://smith.langchain.com.\n",
                "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
                "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c20b48b8-16d7-4089-bc17-f2d240b3935a",
            "metadata": {},
            "source": [
                "### Загрузка документов\n",
                "\n",
                "Используйте `YouTubeLoader` для загрузки транскрипций нескольких видео LangChain:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "ae6921e1-3d5a-431c-9999-29a5f33201e1",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.document_loaders import YoutubeLoader\n",
                "\n",
                "urls = [\n",
                "    \"https://www.youtube.com/watch?v=HAn9vnJy6S4\",\n",
                "    \"https://www.youtube.com/watch?v=dA1cHGACXCo\",\n",
                "    \"https://www.youtube.com/watch?v=ZcEMLz27sL4\",\n",
                "    \"https://www.youtube.com/watch?v=hvAPnpSfSGo\",\n",
                "    \"https://www.youtube.com/watch?v=EhlPDL4QrWY\",\n",
                "    \"https://www.youtube.com/watch?v=mmBo8nlu2j0\",\n",
                "    \"https://www.youtube.com/watch?v=rQdibOsL1ps\",\n",
                "    \"https://www.youtube.com/watch?v=28lC4fqukoc\",\n",
                "    \"https://www.youtube.com/watch?v=es-9MgxB-uc\",\n",
                "    \"https://www.youtube.com/watch?v=wLRHwKuKvOE\",\n",
                "    \"https://www.youtube.com/watch?v=ObIltMaRJvY\",\n",
                "    \"https://www.youtube.com/watch?v=DjuXACWYkkU\",\n",
                "    \"https://www.youtube.com/watch?v=o7C9ld6Ln-M\",\n",
                "]\n",
                "docs = []\n",
                "for url in urls:\n",
                "    docs.extend(YoutubeLoader.from_youtube_url(url, add_video_info=True).load())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "2b84918e",
            "metadata": {},
            "outputs": [],
            "source": [
                "import datetime\n",
                "\n",
                "# Добавление дополнительной метаданных: год публикации видео\n",
                "for doc in docs:\n",
                "    doc.metadata[\"publish_year\"] = int(\n",
                "        datetime.datetime.strptime(\n",
                "            doc.metadata[\"publish_date\"], \"%Y-%m-%d %H:%M:%S\"\n",
                "        ).strftime(\"%Y\")\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ce7da456-3023-4f04-bba1-f7e2c468c7fe",
            "metadata": {},
            "source": [
                "Заголовки загруженных видео хранятся в списке `docs`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "id": "3e1a99ee-1078-4373-b80a-630af48bf94a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['OpenGPTs',\n",
                            " 'Building a web RAG chatbot: using LangChain, Exa (prev. Metaphor), LangSmith, and Hosted Langserve',\n",
                            " 'Streaming Events: Introducing a new `stream_events` method',\n",
                            " 'LangGraph: Multi-Agent Workflows',\n",
                            " 'Build and Deploy a RAG app with Pinecone Serverless',\n",
                            " 'Auto-Prompt Builder (with Hosted LangServe)',\n",
                            " 'Build a Full Stack RAG App With TypeScript',\n",
                            " 'Getting Started with Multi-Modal LLMs',\n",
                            " 'SQL Research Assistant',\n",
                            " 'Skeleton-of-Thought: Building a New Template from Scratch',\n",
                            " 'Benchmarking RAG over LangChain Docs',\n",
                            " 'Building a Research Assistant from Scratch',\n",
                            " 'LangServe and LangChain Templates Webinar']"
                        ]
                    },
                    "execution_count": 59,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "[doc.metadata[\"title\"] for doc in docs]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "05a71032-14c3-4517-aa9a-3a5e88eaeb92",
            "metadata": {},
            "source": [
                "Вы также можете получить доступ к метаданным, связанным с каждым видео.\n",
                "Каждый документ также имеет заголовок, количество просмотров, дату публикации и продолжительность:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "id": "c7748415-ddbf-4c55-a242-c28833c03caf",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'source': 'HAn9vnJy6S4',\n",
                            " 'title': 'OpenGPTs',\n",
                            " 'description': 'Unknown',\n",
                            " 'view_count': 7210,\n",
                            " 'thumbnail_url': 'https://i.ytimg.com/vi/HAn9vnJy6S4/hq720.jpg',\n",
                            " 'publish_date': '2024-01-31 00:00:00',\n",
                            " 'length': 1530,\n",
                            " 'author': 'LangChain',\n",
                            " 'publish_year': 2024}"
                        ]
                    },
                    "execution_count": 60,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "docs[0].metadata"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5db72331-1e79-4910-8faa-473a0e370277",
            "metadata": {},
            "source": [
                "Пример содержимого одного из документов:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "id": "845149b7-130e-4228-ac80-d0a9286ef1d3",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "\"hello today I want to talk about open gpts open gpts is a project that we built here at linkchain uh that replicates the GPT store in a few ways so it creates uh end user-facing friendly interface to create different Bots and these Bots can have access to different tools and they can uh be given files to retrieve things over and basically it's a way to create a variety of bots and expose the configuration of these Bots to end users it's all open source um it can be used with open AI it can be us\""
                        ]
                    },
                    "execution_count": 61,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "docs[0].page_content[:500]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "561697c8-b848-4b12-847c-ab6a8e2d1ae6",
            "metadata": {},
            "source": [
                "### Индексирование документов\n",
                "\n",
                "Каждый раз при извлечении данных нужно создавать индекс документов, к которым можно выполнять запросы.\n",
                "Для индексирования документов используйте векторное хранилище.\n",
                "Перед помещением документов в хранилище их на части, чтобы ваши запросы были более точными и краткими."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "1f621694",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_chroma import Chroma\n",
                "from langchain_openai import OpenAIEmbeddings\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "\n",
                "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
                "chunked_docs = text_splitter.split_documents(docs)\n",
                "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
                "vectorstore = Chroma.from_documents(\n",
                "    chunked_docs,\n",
                "    embeddings,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "483d8d0a-5c1b-46b0-862c-a4eccfd5ae3c",
            "metadata": {},
            "source": [
                "## Извлечение без анализа запросов\n",
                "\n",
                "Вы можете выполнять поиск по сходству с запросом пользователя, для обнаружения подходящих фрагментов."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "id": "09435e9b-57b4-41b1-b34a-449815bdfae0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Build and Deploy a RAG app with Pinecone Serverless\n",
                        "hi this is Lance from the Lang chain team and today we're going to be building and deploying a rag app using pine con serval list from scratch so we're going to kind of walk through all the code required to do this and I'll use these slides as kind of a guide to kind of lay the the ground work um so first what is rag so under capoy has this pretty nice visualization that shows LMS as a kernel of a new kind of operating system and of course one of the core components of our operating system is th\n"
                    ]
                }
            ],
            "source": [
                "search_results = vectorstore.similarity_search(\"how do I build a RAG agent\")\n",
                "print(search_results[0].metadata[\"title\"])\n",
                "print(search_results[0].page_content[:500])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5a79ef1b-7edd-4b68-98e5-c0e4c0dd02e6",
            "metadata": {},
            "source": [
                "Вы можете видеть удовлетворительный результат, соответствующий запросу пользователя.\n",
                "Но что, если вам нужно искать результаты за определенный период времени?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "id": "7adbfc11-ca01-4883-8978-e4f6e4a1d23d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "OpenGPTs\n",
                        "2024-01-31\n",
                        "hardcoded that it will always do a retrieval step here the assistant decides whether to do a retrieval step or not sometimes this is good sometimes this is bad sometimes it you don't need to do a retrieval step when I said hi it didn't need to call it tool um but other times you know the the llm might mess up and not realize that it needs to do a retrieval step and so the rag bot will always do a retrieval step so it's more focused there because this is also a simpler architecture so it's always\n"
                    ]
                }
            ],
            "source": [
                "search_results = vectorstore.similarity_search(\"videos on RAG published in 2023\")\n",
                "print(search_results[0].metadata[\"title\"])\n",
                "print(search_results[0].metadata[\"publish_date\"])\n",
                "print(search_results[0].page_content[:500])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4790e2db-3c6e-440b-b6e8-ebdd6600fda5",
            "metadata": {},
            "source": [
                "Первый результат относится к 2024 году (хотя в запросе задан 2023 год) и не очень релевантен запросу.\n",
                "Поскольку в данном случае выполняется простой поиск по содержимому документов, у вас нет возможности фильтровать результаты по каким-либо атрибутам документа.\n",
                "\n",
                "Это лишь одна проблем, которые могут возникнуть. \n",
                "Рассмотрим, как анализ запросов может ее исправить."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "57396e23-c192-4d97-846b-5eacea4d6b8d",
            "metadata": {},
            "source": [
                "## Анализ запросов\n",
                "\n",
                "Используйте анализ запросов для улучшения результатов поиска.\n",
                "Для этого нужно:\n",
                "\n",
                "- определить схему запроса, которая будет содержать фильтр по датам;\n",
                "- использовать модель, которая способна вызывать функци, для преобразования вопроса пользователя в структурированный запрос.\n",
                "\n",
                "### Схема запроса\n",
                "\n",
                "В представленном примере для даты публикации используются явные атрибуты, которые позволяют задать диапазон для фильтрации."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "0b51dd76-820d-41a4-98c8-893f6fe0d1ea",
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Optional\n",
                "\n",
                "from langchain_core.pydantic_v1 import BaseModel, Field\n",
                "\n",
                "\n",
                "class Search(BaseModel):\n",
                "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
                "\n",
                "    query: str = Field(\n",
                "        ...,\n",
                "        description=\"Similarity search query applied to video transcripts.\",\n",
                "    )\n",
                "    publish_year: Optional[int] = Field(None, description=\"Year video was published\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f8b08c52-1ce9-4d8b-a779-cbe8efde51d1",
            "metadata": {},
            "source": [
                "### Генерация запросов\n",
                "\n",
                "Для преобразования пользовательских вопросов в структурированные запросы в примере используется API вызова инструментов OpenAI.\n",
                "Например, используется новый конструктор [ChatModel.with_structured_output()](/docs/how_to/structured_output) для передачи схемы модели и анализа вывода."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "783c03c3-8c72-4f88-9cf4-5829ce6745d6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/bagatur/langchain/libs/core/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.\n",
                        "  warn_beta(\n"
                    ]
                }
            ],
            "source": [
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.runnables import RunnablePassthrough\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
                "You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
                "Given a question, return a list of database queries optimized to retrieve the most relevant results.\n",
                "\n",
                "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
                "prompt = ChatPromptTemplate.from_messages(\n",
                "    [\n",
                "        (\"system\", system),\n",
                "        (\"human\", \"{question}\"),\n",
                "    ]\n",
                ")\n",
                "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
                "structured_llm = llm.with_structured_output(Search)\n",
                "query_analyzer = {\"question\": RunnablePassthrough()} | prompt | structured_llm"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f403517a-b8e3-44ac-b0a6-02f8305635a2",
            "metadata": {},
            "source": [
                "Посмотрите, какие запросы анализатор генерирует для ранее заданных поисковых вопросов:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "bc1d3863",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Search(query='build RAG agent', publish_year=None)"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "query_analyzer.invoke(\"how do I build a RAG agent\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "af62af17-4f90-4dbd-a8b4-dfff51f1db95",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Search(query='RAG', publish_year=2023)"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "query_analyzer.invoke(\"videos on RAG published in 2023\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c7c65b2f-7881-45fc-a47b-a4eaaf48245f",
            "metadata": {},
            "source": [
                "## Извлечение с анализом запросов\n",
                "\n",
                "Используйте сгенерированные запросы для извлечения данных.\n",
                "\n",
                ":::note\n",
                "\n",
                "В примере указан инструмент `tool_choice=\"Search\"`.\n",
                "Это вынудит LLM вызвать только один инструмент, что приведет к тому, что у вас всегда будет один оптимизированный запрос для поиска.\n",
                "\n",
                "Это не всегда так. В других руководствах вы найдете информацию о том, как поступать в ситуациях, когда не возвращается ни одного или возвращается несколько оптимизированных запросов.\n",
                "\n",
                ":::"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "1e047d87",
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import List\n",
                "\n",
                "from langchain_core.documents import Document"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "8dac7866",
            "metadata": {},
            "outputs": [],
            "source": [
                "def retrieval(search: Search) -> List[Document]:\n",
                "    if search.publish_year is not None:\n",
                "        # This is syntax specific to Chroma,\n",
                "        # the vector database we are using.\n",
                "        _filter = {\"publish_year\": {\"$eq\": search.publish_year}}\n",
                "    else:\n",
                "        _filter = None\n",
                "    return vectorstore.similarity_search(search.query, filter=_filter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "232ad8a7-7990-4066-9228-d35a555f7293",
            "metadata": {},
            "outputs": [],
            "source": [
                "retrieval_chain = query_analyzer | retrieval"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e6a4460c",
            "metadata": {},
            "source": [
                "Запустите полученную цепочку с входными данными, которые привели к проблеме, из примера выше и убедитесь, что она возвращает только результаты за указанный год:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "e7f683b5-b1c5-4dec-b163-2efc162a2b51",
            "metadata": {},
            "outputs": [],
            "source": [
                "results = retrieval_chain.invoke(\"RAG tutorial published in 2023\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "1ad52512-b3e8-42a3-8701-d9e87fb8b46c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[('Getting Started with Multi-Modal LLMs', '2023-12-20 00:00:00'),\n",
                            " ('LangServe and LangChain Templates Webinar', '2023-11-02 00:00:00'),\n",
                            " ('Getting Started with Multi-Modal LLMs', '2023-12-20 00:00:00'),\n",
                            " ('Building a Research Assistant from Scratch', '2023-11-16 00:00:00')]"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "[(doc.metadata[\"title\"], doc.metadata[\"publish_date\"]) for doc in results]"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
