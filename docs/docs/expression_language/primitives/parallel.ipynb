{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b022ab74-794d-4c54-ad47-ff9549ddb9d2",
   "metadata": {},
   "source": [
    "# Преобразобавние данных с помощью RunnableParallel\n",
    "\n",
    "## Преобразование входных и выходных данных\n",
    "\n",
    "Интерфейс RunnableParallel может быть полезен для преобразования выходных данных одного Runnable-интерфейса, в формат входных данных следующего Runnable-интерфейса в последовательности.\n",
    "\n",
    "В примере ниже входные данные для объейта `prompt` должны быть представлены в виде map-структуры с ключами `context` и `question`.\n",
    "При этом, данные введенные пользователем, представляют обычный вопрос.\n",
    "Эти данные передаются в поле `question`, а для получения контекста и заполнения поля `context` используется ретривер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2627ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  gigachain gigachat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "267d1460-53c1-4fdb-b2c3-b6a1eb7fccff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Василий работал в Сбербанке.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "from langchain_community.embeddings.gigachat import GigaChatEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"Василий работал в Сбербанке\"], embedding=GigaChatEmbeddings(credentials=\"<авторизационные_данные>\", verify_ssl_certs=False)\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "template = \"\"\"Отвечай на вопрос только на основе контекста:\n",
    "{context}\n",
    "\n",
    "Вопрос: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = GigaChat(credentials=\"<авторизационные_данные>\", verify_ssl_certs=False)\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieval_chain.invoke(\"Где работал Василий?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cd4c4-e7ed-4ab8-934d-f7a4eca55ee1",
   "metadata": {},
   "source": [
    ":::note\n",
    "\n",
    "Типы преобразуются автоматически, поэтому при соединений интерфейсов RunnableParallel и Runnable не нужно оборачивать словарь в экземпляр класса RunnableParallel.\n",
    "\n",
    "Таким образом, в контексте цепочки оба следующих способа будут работать одинаково:\n",
    "\n",
    ":::\n",
    "\n",
    "```json\n",
    "{\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "```\n",
    "\n",
    "```python\n",
    "RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "```\n",
    "\n",
    "```python\n",
    "RunnableParallel(context=retriever, question=RunnablePassthrough())\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b8baa-3a80-44f0-bb79-d22f79815d3d",
   "metadata": {},
   "source": [
    "## Сокращение кода с помощью itemgetter\n",
    "\n",
    "При работе с `RunnableParallel` вы можете использовать Python-функцию [`itemgetter`](https://docs.python.org/3/library/operator.html#operator.itemgetter), чтобы сократить код, который нужен для извлечения данных из map-структуры.\n",
    "\n",
    "Приведенный пример показывает как использовать `itemgetter` для получения определенных ключей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "84fc49e1-2daf-4700-ae33-a0a6ed47d5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ответ: Vasyа worked at Sberbank.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "from langchain_community.embeddings.gigachat import GigaChatEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"Василий работал в Сбербанке\"], embedding=GigaChatEmbeddings(credentials=\"<авторизационные_данные>\", verify_ssl_certs=False)\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Отвечай на вопрос только на основе контекста:\n",
    "{context}\n",
    "\n",
    "Вопрос: {question}\n",
    "\n",
    "Переведи ответ на заданный язык: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"где работал Вася\", \"language\": \"английский\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f9847-39aa-4fe4-9049-3a8969bc4bce",
   "metadata": {},
   "source": [
    "## Распараллеливание этапов работы\n",
    "\n",
    "RunnableParallel (или RunnableMap) позволяет параллельно выполнять несколько Runnable-интерфейсов и возвращать их выходные данные в виде map-структуры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "31f18442-f837-463f-bef4-8729368f5f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content='Почему облака не любят понедельники? Потому что они всегда идут после субботы и воскресенья.', response_metadata={'token_usage': Usage(prompt_tokens=18, completion_tokens=24, total_tokens=42), 'model_name': 'GigaChat:3.1.24.3', 'finish_reason': 'stop'}),\n",
       " 'poem': AIMessage(content='Облако плывет по небу,\\nСловно белый парус в синеве.\\nПусть оно не знает грусти,\\nПусть оно всегда на высоте!', response_metadata={'token_usage': Usage(prompt_tokens=19, completion_tokens=40, total_tokens=59), 'model_name': 'GigaChat:3.1.24.3', 'finish_reason': 'stop'})}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "\n",
    "model = GigaChat(credentials=\"<авторизационные_данные>\", verify_ssl_certs=False)\n",
    "joke_chain = ChatPromptTemplate.from_template(\"расскажи шутку про {topic}\") | model\n",
    "poem_chain = (\n",
    "    ChatPromptTemplate.from_template(\"напиши короткий стих про {topic}\") | model\n",
    ")\n",
    "\n",
    "map_chain = RunnableParallel(joke=joke_chain, poem=poem_chain)\n",
    "\n",
    "map_chain.invoke({\"topic\": \"облако\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833da249-c0d4-4e5b-b3f8-cab549f0f7e1",
   "metadata": {},
   "source": [
    "## Параллелизм\n",
    "\n",
    "Так как каждый Runnable-интерфейс в map-структуре исполняется параллельно, интерфейс RunnableParallel можно использовать для параллельного выполнения независимых процессов.\n",
    "Так, приведенные выше цепочки  `joke_chain`, `poem_chain` и `map_chain` выполняются примерно одинаковое время, при том, что `map_chain` включает выполнение двух других цепочек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38e47834-45af-4281-991f-86f150001510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01 s ± 385 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "joke_chain.invoke({\"topic\": \"облако\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d0cd40de-b37e-41fa-a2f6-8aaa49f368d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.7 s ± 219 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "poem_chain.invoke({\"topic\": \"облако\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "799894e1-8e18-4a73-b466-f6aea6af3920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.73 s ± 142 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "map_chain.invoke({\"topic\": \"облако\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
