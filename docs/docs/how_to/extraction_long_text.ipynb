{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e161a8a-fcf0-4d55-933e-da271ce28d7e",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Обработка большого текста\n",
    "\n",
    "При обработке текстов, которые превышают размер окна конекста модели:\n",
    "\n",
    "* Смените модель. Попробуйте использовать модель с большим окном контекста, например, [GigaChat Lite+](https://developers.sber.ru/docs/ru/gigachat/models).\n",
    "* Разделите документ на небольшие фрагменты и попробуйте извлечь данные из них.\n",
    "* Используйте RAG — разделите документ на фрагменты и проиндексируйте их. После этого можно будет извлекать данные только из тех фрагментов, которые кажутся модели подходящими.\n",
    "\n",
    "Каждый из способов имеет свои плюсы и минусы, и подходит для решения различных задач."
=======
    "# How to handle long text when doing extraction\n",
    "\n",
    "When working with files, like PDFs, you're likely to encounter text that exceeds your language model's context window. To process this text, consider these strategies:\n",
    "\n",
    "1. **Change LLM** Choose a different LLM that supports a larger context window.\n",
    "2. **Brute Force** Chunk the document, and extract content from each chunk.\n",
    "3. **RAG** Chunk the document, index the chunks, and only extract content from a subset of chunks that look \"relevant\".\n",
    "\n",
    "Keep in mind that these strategies have different trade off and the best strategy likely depends on the application that you're designing!\n",
    "\n",
    "This guide demonstrates how to implement strategies 2 and 3."
>>>>>>> langchan/master
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57969139-ad0a-487e-97d8-cb30e2af9742",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Подготовка\n",
    "\n",
    "В качестве примера используется [статью о машинах из Википедии](https://en.wikipedia.org/wiki/Car), загруженная как документ (`Document`) GigaChain."
=======
    "## Set up\n",
    "\n",
    "We need some example data! Let's download an article about [cars from wikipedia](https://en.wikipedia.org/wiki/Car) and load it as a LangChain [Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html)."
>>>>>>> langchan/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "id": "571aad22-2cec-4b9b-b656-5e4b81a1ec6c",
=======
   "execution_count": 1,
   "id": "84460db2-36e1-4037-bfa6-2a11883c2ba5",
>>>>>>> langchan/master
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import requests\n",
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "\n",
<<<<<<< HEAD
    "# Загрузка статьи\n",
    "response = requests.get(\"https://en.wikipedia.org/wiki/Car\")\n",
    "# Запись в файл\n",
    "with open(\"car.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)\n",
    "# Загрузка файла с помощью парсера HTML\n",
    "loader = BSHTMLLoader(\"car.html\")\n",
    "document = loader.load()[0]\n",
    "# Очистка кода\n",
    "# Замена нескольких последовательных новых строк одной новой строкой\n",
    "document.page_content = re.sub(\"\\n\\n+\", \"\\n\", document.page_content).replace(\n",
    "    \"\\xa0\", \" \"\n",
    ")"
=======
    "# Download the content\n",
    "response = requests.get(\"https://en.wikipedia.org/wiki/Car\")\n",
    "# Write it to a file\n",
    "with open(\"car.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)\n",
    "# Load it with an HTML parser\n",
    "loader = BSHTMLLoader(\"car.html\")\n",
    "document = loader.load()[0]\n",
    "# Clean up code\n",
    "# Replace consecutive new lines with a single new line\n",
    "document.page_content = re.sub(\"\\n\\n+\", \"\\n\", document.page_content)"
>>>>>>> langchan/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "85656454-6d5d-4ff6-93ca-690791ac1ec4",
=======
   "execution_count": 2,
   "id": "fcb6917b-123d-4630-a0ce-ed8b293d482d",
>>>>>>> langchan/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "79251\n"
=======
      "79174\n"
>>>>>>> langchan/master
     ]
    }
   ],
   "source": [
    "print(len(document.page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3ffb8d-587a-4370-886a-e56e617bcb9c",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Определение схемы данных\n",
    "\n",
    "Определение схемы данных, которые нужно извлечь из текста."
=======
    "## Define the schema\n",
    "\n",
    "Following the [extraction tutorial](/docs/tutorials/extraction), we will use Pydantic to define the schema of information we wish to extract. In this case, we will extract a list of \"key developments\" (e.g., important historical events) that include a year and description.\n",
    "\n",
    "Note that we also include an `evidence` key and instruct the model to provide in verbatim the relevant sentences of text from the article. This allows us to compare the extraction results to (the model's reconstruction of) text from the original document."
>>>>>>> langchan/master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b288ed-87a6-4af0-aac8-20921dc370d4",
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikelarg/Projects/gigachain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_community.chat_models.gigachat import GigaChat\n",
=======
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
>>>>>>> langchan/master
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class KeyDevelopment(BaseModel):\n",
<<<<<<< HEAD
    "    \"\"\"Важная историческая дата.\"\"\"\n",
    "\n",
    "    # Док-строка выше, передается в описании функции\n",
    "    # и помогает улучшить результаты работы LLM\n",
    "\n",
    "    # Обратите внимание:\n",
    "    # У каждого поля есть описание (`description`), которое передается в модель, в описании аргументов функции.\n",
    "    # Хорошее пописание помогает повысить качество извлечения.\n",
    "    year: Optional[int] = Field(\n",
    "        ..., description=\"Год исторического события. Не может быть null.\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        ..., description=\"Описание. Что произошло в этом году? Каково было развитие?\"\n",
    "    )\n",
    "    evidence: str = Field(\n",
    "        ...,\n",
    "        description=\"Повтори дословно предложения из текста, из которых были извлечены год и описание.\",\n",
=======
    "    \"\"\"Information about a development in the history of cars.\"\"\"\n",
    "\n",
    "    year: int = Field(\n",
    "        ..., description=\"The year when there was an important historic development.\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        ..., description=\"What happened in this year? What was the development?\"\n",
    "    )\n",
    "    evidence: str = Field(\n",
    "        ...,\n",
    "        description=\"Repeat in verbatim the sentence(s) from which the year and description information were extracted\",\n",
>>>>>>> langchan/master
    "    )\n",
    "\n",
    "\n",
    "class ExtractionData(BaseModel):\n",
<<<<<<< HEAD
    "    \"\"\"Извлеченая информация о ключевых событиях в истории.\"\"\"\n",
=======
    "    \"\"\"Extracted information about key developments in the history of cars.\"\"\"\n",
>>>>>>> langchan/master
    "\n",
    "    key_developments: List[KeyDevelopment]\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "# Определяем промпт: добавляем инструкции и дополнительный контекст\n",
    "# На этом этапе можно:\n",
    "# * Добавить примеры работы функций, для улучшения качества извлечения информации\n",
    "# * Предоставить дополнительную информацию о том какие данные и откуда будут извлекаться\n",
=======
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
>>>>>>> langchan/master
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
<<<<<<< HEAD
    "            \"Ты эксперт в извлечении важных исторических дат из текста. \"\n",
    "            \"Извлекай только важные исторические события с годами.\"\n",
    "            \"Если ты не можешь извлечь год, не записывай это в историческое событие\",\n",
    "        ),\n",
    "        MessagesPlaceholder(\n",
    "            \"examples\"\n",
    "        ),  # В блоках ниже показано как использовать примеры для повышения качества извлечения данных\n",
=======
    "            \"You are an expert at identifying key historic development in text. \"\n",
    "            \"Only extract important historic developments. Extract nothing if no important information can be found in the text.\",\n",
    "        ),\n",
>>>>>>> langchan/master
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909e22e-8a00-4f3d-bbf2-4762a0558af3",
   "metadata": {},
   "source": [
    "## Create an extractor\n",
    "\n",
<<<<<<< HEAD
    "llm = GigaChat(\n",
    "    verify_ssl_certs=False,\n",
    "    timeout=6000,\n",
    "    model=\"GigaChat-Pro\",\n",
    "    temperature=0.01,\n",
    ")\n",
=======
    "Let's select an LLM. Because we are using tool-calling, we will need a model that supports a tool-calling feature. See [this table](/docs/integrations/chat) for available LLMs.\n",
    "\n",
    "```{=mdx}\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
>>>>>>> langchan/master
    "\n",
    "<ChatModelTabs\n",
    "  customVarName=\"llm\"\n",
    "  openaiParams={`model=\"gpt-4-0125-preview\", temperature=0`}\n",
    "/>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "109f4f05-d0ff-431d-93d9-8f5aa34979a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-0125-preview\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4ae224-6d3d-4fe2-b210-7db19a9fe580",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = prompt | llm.with_structured_output(\n",
    "    schema=ExtractionData,\n",
<<<<<<< HEAD
=======
    "    include_raw=False,\n",
>>>>>>> langchan/master
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aebafb-26b5-42b2-ae8e-9c05cd56e5c5",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Разделение файла на фрагменты\n",
    "\n",
    "Разделение файла на фрагменты, которые помещаются в окно контекста модели."
=======
    "## Brute force approach\n",
    "\n",
    "Split the documents into chunks such that each chunk fits into the context window of the LLMs."
>>>>>>> langchan/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 7,
>>>>>>> langchan/master
   "id": "27b8a373-14b3-45ea-8bf5-9749122ad927",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Управление размером каждого фрагмента\n",
    "    chunk_size=2000,\n",
    "    # Управление перекрытием между фрагментами\n",
=======
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    # Controls the size of each chunk\n",
    "    chunk_size=2000,\n",
    "    # Controls overlap between chunks\n",
>>>>>>> langchan/master
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(document.page_content)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import List, TypedDict\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    ")\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "#\n",
    "# В этом блоке добавляются примеры работы функций для повышения качества извлечения данных\n",
    "# Подробнее о примерах работы — в example.ipynb\n",
    "#\n",
    "\n",
    "\n",
    "class Example(TypedDict):\n",
    "    \"\"\"Пример работы функций.\"\"\"\n",
    "\n",
    "    input: str  # Пример вызова\n",
    "    function_calls: List[BaseModel]  # Pydantic-модель с примером извлечения\n",
    "    function_outputs: List[str]\n",
    "\n",
    "\n",
    "def tool_example_to_messages(example: Example) -> List[BaseMessage]:\n",
    "    \"\"\"Превращаем примеры вызовов функций в историю сообщений\"\"\"\n",
    "    messages: List[BaseMessage] = [HumanMessage(content=example[\"input\"])]\n",
    "    for function_call, function_output in itertools.zip_longest(\n",
    "        example[\"function_calls\"], example.get(\"function_outputs\", [])\n",
    "    ):\n",
    "        messages.append(\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                additional_kwargs={\n",
    "                    \"function_call\": {\n",
    "                        # Сейчас название модели соответствует pydantic-модели\n",
    "                        # В текущий момент в API это неочевидно и будет улучшено.\n",
    "                        \"name\": function_call.__class__.__name__,\n",
    "                        \"arguments\": function_call.dict(),\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        output = \"You have correctly called this tool.\"\n",
    "        if function_output:\n",
    "            output = function_output\n",
    "        messages.append(\n",
    "            FunctionMessage(name=function_call.__class__.__name__, content=output)\n",
    "        )\n",
    "    return messages\n",
    "\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"Техногенная авария «Размыв» Ленинградского-Петербургского метрополитена \"\n",
    "        \"является крупнейшей в мировой практике метростроения[34]; была экранизирована \"\n",
    "        \"в фильме «Прорыв» и послужила вдохновением для фильма «Метро»[35].\",\n",
    "        ExtractionData(\n",
    "            key_developments=[\n",
    "                KeyDevelopment(\n",
    "                    year=None,\n",
    "                    description=\"Техногенная авария 'Размыв' в \"\n",
    "                    \"Ленинградском-Петербургском метрополитене является \"\n",
    "                    \"крупнейшей в мировой практике метростроения\",\n",
    "                    evidence=\"была экранизирована в фильме 'Прорыв' и послужила \"\n",
    "                    \"вдохновением для фильма 'Метро'\",\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        \"\"\"pydantic.v1.error_wrappers.ValidationError: 1 validation error for KeyDevelopment\n",
    "year\n",
    "  none is not an allowed value (type=type_error.none.not_allowed)\"\"\",\n",
    "    ),\n",
    "    (\n",
    "        \"In 1891, Auguste Doriot and his Peugeot colleague Louis Rigoulot completed \"\n",
    "        \"the longest trip by a petrol-driven vehicle when their self-designed and \"\n",
    "        \"built Daimler powered Peugeot Type 3 completed 2,100 kilometres (1,300 mi) \"\n",
    "        \"from Valentigney to Paris and Brest and back again. They were attached to \"\n",
    "        \"the first Paris–Brest–Paris bicycle race, but finished six days \"\n",
    "        \"after the winning cyclist, Charles Terront.\",\n",
    "        ExtractionData(\n",
    "            key_developments=[\n",
    "                KeyDevelopment(\n",
    "                    year=1891,\n",
    "                    description=\"Август Дорио и его коллега Луи Риголу \"\n",
    "                    \"завершают самую длинную поездку на бензиновом автомобиле\",\n",
    "                    evidence=\"In 1891, Auguste Doriot and his Peugeot colleague Louis Rigoulot completed the longest trip by a petrol-driven vehicle\",\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        \"You have correctly called this tool.\",\n",
    "    ),\n",
    "    (\n",
    "        \"I love cats and dogs.\",\n",
    "        ExtractionData(key_developments=[]),\n",
    "        \"You have correctly called this tool.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "for text, tool_call, function_output in examples:\n",
    "    messages.extend(\n",
    "        tool_example_to_messages(\n",
    "            {\n",
    "                \"input\": text,\n",
    "                \"function_calls\": [tool_call],\n",
    "                \"function_outputs\": [function_output],\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
=======
>>>>>>> langchan/master
   "cell_type": "markdown",
   "id": "5b43d7e0-3c85-4d97-86c7-e8c984b60b0a",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Используйте метод `.batch`, для параллельного извлечения данных из каждого фрагмента.\n",
    "\n",
    "<!--\n",
    ":::note\n",
    "\n",
    "You can often use .batch() to parallelize the extractions! `batch` uses a threadpool under the hood to help you parallelize workloads.\n",
    "\n",
    "If your model is exposed via an API, this will likley speed up your extraction flow!\n",
    "\n",
    ":::\n",
    "-->"
=======
    "Use [batch](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.Runnable.html) functionality to run the extraction in **parallel** across each chunk! \n",
    "\n",
    ":::{.callout-tip}\n",
    "You can often use .batch() to parallelize the extractions! `.batch` uses a threadpool under the hood to help you parallelize workloads.\n",
    "\n",
    "If your model is exposed via an API, this will likely speed up your extraction flow!\n",
    ":::"
>>>>>>> langchan/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "6ba766b5-8d6c-48e6-8d69-f391a66b65d2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Добавьте ограничение на работу с первыми тремя фрагментами\n",
    "# чтобы можно было быстро перезапускать код\n",
    "first_few = texts[:10]\n",
    "\n",
    "extractions = extractor.batch(\n",
    "    [{\"text\": text, \"examples\": messages} for text in first_few],\n",
    "    {\n",
    "        \"max_concurrency\": 5\n",
    "    },  # ограничьте конкурентность с помощью параметра max_concurrency\n",
=======
   "execution_count": 8,
   "id": "6ba766b5-8d6c-48e6-8d69-f391a66b65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit just to the first 3 chunks\n",
    "# so the code can be re-run quickly\n",
    "first_few = texts[:3]\n",
    "\n",
    "extractions = extractor.batch(\n",
    "    [{\"text\": text} for text in first_few],\n",
    "    {\"max_concurrency\": 5},  # limit the concurrency by passing max concurrency!\n",
>>>>>>> langchan/master
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da8904-e927-406b-a439-2a16f6087ccf",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### Объединение результатов\n",
    "\n",
    "После извлечения данных из разных фрагментов их нужно объединить в общий результат."
=======
    "### Merge results\n",
    "\n",
    "After extracting data from across the chunks, we'll want to merge the extractions together."
>>>>>>> langchan/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "id": "30b35897-4d94-44ad-80c6-446eff61b76b",
=======
   "execution_count": 9,
   "id": "c3f77470-ce6c-477f-8957-650913218632",
>>>>>>> langchan/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "[KeyDevelopment(year=None, description='Car, or an automobile, is a motor vehicle with wheels.', evidence='A car, or an automobile, is a motor vehicle with wheels.'),\n",
       " KeyDevelopment(year=1769, description='Французский изобретатель Николя-Жозеф Кюньо создал первый паровой автомобиль в 1769 году', evidence='French inventor Nicolas-Joseph Cugnot built the first steam-powered road vehicle in 1769'),\n",
       " KeyDevelopment(year=1886, description='Немецкий изобретатель Карл Бенц запатентовал свой Benz Patent-Motorwagen в 1886 году', evidence='The modern car—a practical, marketable automobile for everyday use—was invented in 1886, when German inventor Carl Benz patented his Benz Patent-Motorwagen.'),\n",
       " KeyDevelopment(year=1908, description='Модель Т, американский автомобиль, произведенный компанией Ford Motor Company, стал доступным для масс в 1908 году', evidence='One of the first cars affordable by the masses was the 1908 Model T, an American car manufactured by the Ford Motor Company.'),\n",
       " KeyDevelopment(year=1897, description=\"Автомобиль - классический композит, полученный из древнегреческого autós (αὐτός) 'сам' и латинского mobilis 'передвижной', вошел в английский язык из французского и был впервые принят Автомобильным клубом Великобритании в 1897 году.\", evidence='\"Automobile\", a classical compound derived from Ancient Greek autós (αὐτός) \"self\" and Latin mobilis \"movable\", entered English from French and was first adopted by the Automobile Club of Great Britain in 1897.[20]'),\n",
       " KeyDevelopment(year=1678, description='Первая паровая машина Вербиста, в 1678 году (Фердинанд Вербист)', evidence='Steam machine of Verbiest, in 1678 (Ferdinand Verbiest)'),\n",
       " KeyDevelopment(year=1771, description='Фардиер Кюньо 1771 года, сохранившийся в Музее искусств и ремесел в Париже', evidence=\"Cugnot's 1771 fardier à vapeur, as preserved at the Musée des Arts et Métiers, Paris\"),\n",
       " KeyDevelopment(year=1885, description='Карл Бенц, изобретатель современного автомобиля', evidence='The original Benz Patent-Motorwagen, the first modern car, built in 1885 and awarded the patent for the concept'),\n",
       " KeyDevelopment(year=None, description='Берта Бенц, первый водитель на дальние расстояния', evidence='Bertha Benz, the first long distance driver'),\n",
       " KeyDevelopment(year=None, description='Флокен Электроваген был первым четырехколесным электрическим автомобилем', evidence='The Flocken Elektrowagen was the first four-wheeled electric car'),\n",
       " KeyDevelopment(year=None, description='Штутгарт, колыбель автомобиля[24][25], где Готтлиб Даймлер и Вильгельм Майбах работали в Даймлер Моторен Гезельшафт, и место современных штаб-квартир Мерседес-Бенц Групп и Порше', evidence='Stuttgart, a cradle of the car[24][25] with Gottlieb Daimler and Wilhelm Maybach working there at the Daimler Motoren Gesellschaft and place of the modern day headquarters of Mercedes-Benz Group and Porsche'),\n",
       " KeyDevelopment(year=1769, description='Николя-Жозеф Кюньо создал первый полноразмерный самоходный механический автомобиль в 1769 году.', evidence='Nicolas-Joseph Cugnot is widely credited with building the first full-scale, self-propelled mechanical vehicle in about 1769'),\n",
       " KeyDevelopment(year=1801, description=\"Ричард Тревитик построил и продемонстрировал свою дорожную паровую машину 'Дьявол с пыхтением' в 1801 году.\", evidence='In 1801, Richard Trevithick built and demonstrated his Puffing Devil road locomotive'),\n",
       " KeyDevelopment(year=1807, description='Ньепс и его брат Клауд создали первый в мире двигатель внутреннего сгорания в 1807 году.', evidence=\"In 1807, Nicéphore Niépce and his brother Claude created what was probably the world's first internal combustion engine\"),\n",
       " KeyDevelopment(year=1881, description='Густав Труве демонстрирует трехколесный электромобиль на Международной электротехнической выставке', evidence='В ноябре 1881 года французский изобретатель Густав Труве продемонстрировал трехколесный автомобиль, работающий на электричестве, на Международной электротехнической выставке'),\n",
       " KeyDevelopment(year=1886, description='Карл Бенц патентует свой Benz Patent-Motorwagen', evidence='В 1886 году немец Карл Бенц получил патент на свой Benz Patent-Motorwagen'),\n",
       " KeyDevelopment(year=1888, description='Берта Бенц совершает первую поездку на автомобиле', evidence='В августе 1888 года Берта Бенц, жена Карла Бенца, совершила первую поездку на автомобиле, чтобы доказать его пригодность для дорог'),\n",
       " KeyDevelopment(year=1890, description='Даймлер и Майбах основали Даймлер Моторен Гезельшафт (DMG) в Каннштадте в 1890 году', evidence='Daimler and Maybach founded Daimler Motoren Gesellschaft (DMG) in Cannstatt in 1890'),\n",
       " KeyDevelopment(year=1896, description='Бенц разработал и запатентовал первый внутренне-сгораемый плоский двигатель', evidence='In 1896, Benz designed and patented the first internal-combustion flat engine'),\n",
       " KeyDevelopment(year=1899, description='Бенц был самым большим автомобильным производителем в мире', evidence='Benz was the largest car company in the world with 572 units produced in 1899')]"
      ]
     },
     "execution_count": 11,
=======
       "[KeyDevelopment(year=1966, description='The Toyota Corolla began production, becoming the best-selling series of automobile in history.', evidence='The Toyota Corolla, which has been in production since 1966, is the best-selling series of automobile in history.'),\n",
       " KeyDevelopment(year=1769, description='Nicolas-Joseph Cugnot built the first steam-powered road vehicle.', evidence='The French inventor Nicolas-Joseph Cugnot built the first steam-powered road vehicle in 1769.'),\n",
       " KeyDevelopment(year=1808, description='François Isaac de Rivaz designed and constructed the first internal combustion-powered automobile.', evidence='the Swiss inventor François Isaac de Rivaz designed and constructed the first internal combustion-powered automobile in 1808.'),\n",
       " KeyDevelopment(year=1886, description='Carl Benz patented his Benz Patent-Motorwagen, inventing the modern car.', evidence='The modern car—a practical, marketable automobile for everyday use—was invented in 1886, when the German inventor Carl Benz patented his Benz Patent-Motorwagen.'),\n",
       " KeyDevelopment(year=1908, description='Ford Model T, one of the first cars affordable by the masses, began production.', evidence='One of the first cars affordable by the masses was the Ford Model T, begun in 1908, an American car manufactured by the Ford Motor Company.'),\n",
       " KeyDevelopment(year=1888, description=\"Bertha Benz undertook the first road trip by car to prove the road-worthiness of her husband's invention.\", evidence=\"In August 1888, Bertha Benz, the wife of Carl Benz, undertook the first road trip by car, to prove the road-worthiness of her husband's invention.\"),\n",
       " KeyDevelopment(year=1896, description='Benz designed and patented the first internal-combustion flat engine, called boxermotor.', evidence='In 1896, Benz designed and patented the first internal-combustion flat engine, called boxermotor.'),\n",
       " KeyDevelopment(year=1897, description='Nesselsdorfer Wagenbau produced the Präsident automobil, one of the first factory-made cars in the world.', evidence='The first motor car in central Europe and one of the first factory-made cars in the world, was produced by Czech company Nesselsdorfer Wagenbau (later renamed to Tatra) in 1897, the Präsident automobil.'),\n",
       " KeyDevelopment(year=1890, description='Daimler Motoren Gesellschaft (DMG) was founded by Daimler and Maybach in Cannstatt.', evidence='Daimler and Maybach founded Daimler Motoren Gesellschaft (DMG) in Cannstatt in 1890.'),\n",
       " KeyDevelopment(year=1891, description='Auguste Doriot and Louis Rigoulot completed the longest trip by a petrol-driven vehicle with a Daimler powered Peugeot Type 3.', evidence='In 1891, Auguste Doriot and his Peugeot colleague Louis Rigoulot completed the longest trip by a petrol-driven vehicle when their self-designed and built Daimler powered Peugeot Type 3 completed 2,100 kilometres (1,300 mi) from Valentigney to Paris and Brest and back again.')]"
      ]
     },
     "execution_count": 9,
>>>>>>> langchan/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_developments = []\n",
    "\n",
    "for extraction in extractions:\n",
    "    key_developments.extend(extraction.key_developments)\n",
    "\n",
    "key_developments[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48afd4a7-abcd-48b4-8ff1-6ca485f529e3",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Использование методики RAG\n",
    "\n",
    "Вы также можете проиндексировать фрагменты текста и извлекать данные только из наиболее подходящих из них.\n",
    "\n",
    ":::caution\n",
    "\n",
    "При определении подходящих фрагментов могут возникнуть проблемы.\n",
    "\n",
    "Так, при работе с представленной статьей их Википедии этот подход может привести к потере многих данных, так как фрагменты будут опознаны как не подходящие.\n",
    "\n",
    "Попробуйте использовать подход для решения своих задач, чтобы понять подходит он вам или нет.\n",
    "\n",
    ":::\n",
    "\n",
    "Простой пример, использующий векторное хранилище `FAISS`."
=======
    "## RAG based approach\n",
    "\n",
    "Another simple idea is to chunk up the text, but instead of extracting information from every chunk, just focus on the the most relevant chunks.\n",
    "\n",
    ":::{.callout-caution}\n",
    "It can be difficult to identify which chunks are relevant.\n",
    "\n",
    "For example, in the `car` article we're using here, most of the article contains key development information. So by using\n",
    "**RAG**, we'll likely be throwing out a lot of relevant information.\n",
    "\n",
    "We suggest experimenting with your use case and determining whether this approach works or not.\n",
    ":::\n",
    "\n",
    "To implement the RAG based approach: \n",
    "\n",
    "1. Chunk up your document(s) and index them (e.g., in a vectorstore);\n",
    "2. Prepend the `extractor` chain with a retrieval step using the vectorstore.\n",
    "\n",
    "Here's a simple example that relies on the `FAISS` vectorstore."
>>>>>>> langchan/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 10,
>>>>>>> langchan/master
   "id": "aaf37c82-625b-4fa1-8e88-73303f08ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
<<<<<<< HEAD
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
=======
    "from langchain_core.runnables import RunnableLambda\n",
>>>>>>> langchan/master
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "texts = text_splitter.split_text(document.page_content)\n",
    "vectorstore = FAISS.from_texts(texts, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
<<<<<<< HEAD
    "    search_kwargs={\"k\": 3}\n",
    ")  # Извлечение данных только из этого документа"
=======
    "    search_kwargs={\"k\": 1}\n",
    ")  # Only extract from first document"
>>>>>>> langchan/master
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ecad9-f80f-477c-b954-494b46a02a07",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "В приведенном примере RAG-экстрактор извлекает данные только из начала документа."
=======
    "In this case the RAG extractor is only looking at the top document."
>>>>>>> langchan/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 11,
>>>>>>> langchan/master
   "id": "47aad00b-7013-4f7f-a1b0-02ef269093bf",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "\n",
    "rag_extractor = {\n",
    "    \"text\": retriever | combine_docs,  # получение содержимого начала документа\n",
    "    \"examples\": lambda x: messages,\n",
=======
    "rag_extractor = {\n",
    "    \"text\": retriever | (lambda docs: docs[0].page_content)  # fetch content of top doc\n",
>>>>>>> langchan/master
    "} | extractor"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
   "id": "68f2de01-0cd8-456e-a959-db236189d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    }
   ],
   "source": [
    "results = rag_extractor.invoke(\"Key developments\")"
=======
   "execution_count": 12,
   "id": "68f2de01-0cd8-456e-a959-db236189d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = rag_extractor.invoke(\"Key developments associated with cars\")"
>>>>>>> langchan/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
   "id": "56f434ea-1869-4192-914e-3ccf64e72f75",
=======
   "execution_count": 13,
   "id": "1788e2d6-77bb-417f-827c-eb96c035164e",
>>>>>>> langchan/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "year=2018 description='Рост популярности автомобилей и поездок привел к заторам на дорогах.' evidence='Так, Москва, Стамбул, Богота, Мехико и Сан-Паулу были самыми загруженными городами в 2018 году, согласно данным компании INRIX, специализирующейся на анализе данных.'\n",
      "year=1924 description='В Европе происходило то же самое.' evidence='Morris начал производство на конвейере в Ковли в 1924 году и вскоре стал продавать больше автомобилей, чем Ford, а также начал следовать практике вертикальной интеграции Ford, покупая двигатели, коробки передач и радиаторы у других компаний.'\n",
      "year=None description='В Японии производство автомобилей было ограничено до Второй мировой войны.' evidence='Только несколько компаний производили автомобили в ограниченном количестве, и эти автомобили были небольшими, трехколесными для коммерческих целей или были результатом партнерства с европейскими компаниями.'\n",
      "year=None description='Большинство автомобилей, используемых в начале 2020-х годов, работают на бензине, который сжигается в двигателе внутреннего сгорания.' evidence='Международная организация производителей моторных транспортных средств заявляет, что в странах, где требуется низкосернистый бензин, автомобили, работающие на бензине и соответствующие стандартам поздних 2010-х годов, например, Евро-6, выделяют очень мало локальных загрязнителей воздуха.'\n",
      "year=2021 description='Девять процентов всех проданных в 2021 году автомобилей были электрическими.' evidence='К концу 2021 года в мире насчитывалось более 16 миллионов электромобилей.'\n"
=======
      "year=1869 description='Mary Ward became one of the first documented car fatalities in Parsonstown, Ireland.' evidence='Mary Ward became one of the first documented car fatalities in 1869 in Parsonstown, Ireland,'\n",
      "year=1899 description=\"Henry Bliss one of the US's first pedestrian car casualties in New York City.\" evidence=\"Henry Bliss one of the US's first pedestrian car casualties in 1899 in New York City.\"\n",
      "year=2030 description='All fossil fuel vehicles will be banned in Amsterdam.' evidence='all fossil fuel vehicles will be banned in Amsterdam from 2030.'\n"
>>>>>>> langchan/master
     ]
    }
   ],
   "source": [
    "for key_development in results.key_developments:\n",
    "    print(key_development)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36e626-cf5d-4324-ba29-9bd602be9b97",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Известные проблемы\n",
    "\n",
    "При реализации каждого из подходов вы можете столкнуться со следующими проблемами:\n",
    "\n",
    "* При делении текста на фрагметы модель возможно не сможет извлечь нужные данные, если они встречаются в разных фрагментах.\n",
    "* Большое перекрытие между фрагментами может привести к задвоению информации.\n",
    "* Модели могут придумывать данные."
=======
    "## Common issues\n",
    "\n",
    "Different methods have their own pros and cons related to cost, speed, and accuracy.\n",
    "\n",
    "Watch out for these issues:\n",
    "\n",
    "* Chunking content means that the LLM can fail to extract information if the information is spread across multiple chunks.\n",
    "* Large chunk overlap may cause the same information to be extracted twice, so be prepared to de-duplicate!\n",
    "* LLMs can make up data. If looking for a single fact across a large text and using a brute force approach, you may end up getting more made up data."
>>>>>>> langchan/master
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
