{
 "cells": [
  {
   "cell_type": "raw",
   "id": "63ee3f93",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 0\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9316da0d",
   "metadata": {},
   "source": [
    "# Разработка простого LLM-приложения\n",
    "\n",
    "В этом разделе показан пример разрбаотки LLM-приложения, которое переводит текст с английского языка на другой язык.\n",
    "Итоговое приложение включает всего один вызов LLM плюс некоторую работу с промптами.\n",
    "Это довольно простое приложение, но оно показывает, что множество функций можно реализовать только с помощью промптов и вызова LLM.\n",
    "\n",
    "## Основные понятия\n",
    "\n",
    "В разеделе расмотрены следующие основные понятия:\n",
    "\n",
    "- использование [языковых моделей](/docs/concepts/#chat-models);\n",
    "\n",
    "- использование [шаблонов промптов](/docs/concepts/#prompt-templates) и [парсеров вывода](/docs/concepts/#output-parsers);\n",
    "\n",
    "- [объединение в цепочку](/docs/concepts/#langchain-expression-language) шаблона промптов + LLM + парсера вывода с помощью GigaChain\n",
    "\n",
    "- Развертывание вашего приложения с [LangServe](/docs/concepts/#langserve).\n",
    "<!--\n",
    "- Отладка и трассировка вашего приложения с помощью [LangSmith](/docs/concepts/#langsmith)\n",
    "-->\n",
    "\n",
    "## Подготовка к разработке\n",
    "\n",
    "### Jupyter-блокноты\n",
    "\n",
    "Это руководство, как и большинство других в документации, использует [Jupyter-блокноты](https://jupyter.org/). Они отлично подходят для изучения работы с LLM-системами, так как предоставляют интерактивную среду для работы с руководствами и позволяют работать с непредвиденными ситуациями: недоступностью API, нетипичным выводом и другими.\n",
    "\n",
    "Подробнее об установке jupyter — в [официальной документации](https://jupyter.org/install).\n",
    "\n",
    "### Установка\n",
    "\n",
    "Для установки GigaChain выполните команды:\n",
    "\n",
    "```{=mdx}\n",
    "import Tabs from '@theme/Tabs';\n",
    "import TabItem from '@theme/TabItem';\n",
    "import CodeBlock from \"@theme/CodeBlock\";\n",
    "\n",
    "<Tabs>\n",
    "  <TabItem value=\"pip\" label=\"Pip\" default>\n",
    "    <CodeBlock language=\"bash\">pip install langchain</CodeBlock>\n",
    "  </TabItem>\n",
    "  <TabItem value=\"conda\" label=\"Conda\">\n",
    "    <CodeBlock language=\"bash\">conda install langchain -c conda-forge</CodeBlock>\n",
    "  </TabItem>\n",
    "</Tabs>\n",
    "```\n",
    "\n",
    "\n",
    "Подробнее об установке — в разделе [Установка](https://developers.sber.ru/docs/ru/gigachain/get-started/installation).\n",
    "\n",
    "<!--\n",
    "### LangSmith\n",
    "\n",
    "Многие приложения, которые вы создаете с помощью LangChain, будут содержать несколько шагов с многократными вызовами LLM.\n",
    "По мере усложнения этих приложений становится важно иметь возможность инспектировать, что именно происходит внутри вашей цепочки или агента.\n",
    "Лучший способ сделать это — с помощью [LangSmith](https://smith.langchain.com).\n",
    "\n",
    "После регистрации по ссылке выше, убедитесь, что вы установили переменные среды для начала ведения журнала трассировок:\n",
    "\n",
    "```shell\n",
    "export LANGCHAIN_TRACING_V2=\"true\"\n",
    "export LANGCHAIN_API_KEY=\"...\"\n",
    "```\n",
    "\n",
    "Или, если вы работаете в ноутбуке, вы можете установить их с помощью:\n",
    "\n",
    "```python\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "```\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5558ca9",
   "metadata": {},
   "source": [
    "## Разбор примера\n",
    "\n",
    "В разделе приводится пример разработки приложения для перевода пользовательского ввода с одного языка на другой.\n",
    "\n",
    "## Использование языковых моделей\n",
    "\n",
    "В первую очередь нужно подключить языковую модель.\n",
    "GigaChain поддерживает различные языковые модели, которые могут заменять друг друга.\n",
    "\n",
    "```{=mdx}\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs openaiParams={`model=\"gpt-4\"`} />\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b41234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5642ff",
   "metadata": {},
   "source": [
    "Сначала попробуйте использовать модель напрямую.\n",
    "`ChatModel` — это экземпляры Runnable-интерфейса GigaChain, что означает, что для работы они они предоставляют стандартный интерфейс.\n",
    "Для простого вызова модели, вы можете передать список сообщений в метод `.invoke`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b2481f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ciao!', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 20, 'total_tokens': 23}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-fc5d7c88-9615-48ab-a3c7-425232b562c5-0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83373db",
   "metadata": {},
   "source": [
    "<!--\n",
    "Если мы включили LangSmith, мы можем увидеть, что этот запуск зарегистрирован в LangSmith, и просмотреть [трассировку LangSmith](https://smith.langchain.com/public/88baa0b2-7c1a-4d09-ba30-a47985dde2ea/r).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd03ed",
   "metadata": {},
   "source": [
    "## Парсеры вывода OutputParsers\n",
    "\n",
    "Ответ от модели — это экземпляр класса `AIMessage`.\n",
    "Такое сообщение содержит строковый ответ вместе с дополнительной информацией об ответе.\n",
    "Часто для работы нужен только строковый ответ.\n",
    "Для его получения вы можете использовать парсер вывода.\n",
    "\n",
    "Импортируйте простой парсер вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7ae9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaebe33a",
   "metadata": {},
   "source": [
    "Парсер можно использовать отдельно от других компонентов приложения.\n",
    "Например, вы можете сохранить результат вызова языковой модели и затем передать его в парсер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bacb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efb8da87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d508b79d",
   "metadata": {},
   "source": [
    "Тем не менее, гораздо чаще парсер вывода объединяется в цепочку с моделью.\n",
    "В таком случае он будет вызываться каждый раз при обращении к цепочке.\n",
    "Полученная цепочка будет принимать на вход тип данных языковой модели (строку или список сообщений) и возвращать тип данных парсера вывода (строка).\n",
    "\n",
    "Для создания цепочки, используйте оператор `|`.\n",
    "GigaChain использует этот оператор для объединения двух элементов вместе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9449cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e82f933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd009096",
   "metadata": {},
   "source": [
    "<!--\n",
    "Если мы теперь посмотрим на LangSmith, мы увидим, что цепочка состоит из двух шагов: сначала вызывается языковая модель, затем результат передается парсеру вывода. Мы можем увидеть [трассировку LangSmith](https://smith.langchain.com/public/f1bdf656-2739-42f7-ac7f-0f1dd712322f/r).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab8da31",
   "metadata": {},
   "source": [
    "## Шаблоны промптов\n",
    "\n",
    "На данный момент в примере список сообщений передается напрямую в языковую модель.\n",
    "Как правило список сообщений формируется из комбинации ввода пользователя и логики приложения.\n",
    "Эта логика обычно принимает необработанный ввод и преобразует его в список сообщений, готовых для передачи в языковую модель.\n",
    "Типичные преобразования включают добавление системного сообщения или изменение шаблона с учетом ввода пользователя.\n",
    "\n",
    "Шаблоны промптов (PromptTemplates) — это конструкции GigaChain, которые принимают необработанный ввод пользователя и возвращают данные (промпт), готовые для передачи в языковую модель.\n",
    "\n",
    "Создайте шаблон промпта, который будет принимать две пользовательские переменные:\n",
    "\n",
    "- `language` — язык, на который нужно перевести текст;\n",
    "- `text` — текст для перевода.\n",
    "\n",
    "Для этого импортируйте `ChatPromptTemplate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e73cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e876c2a",
   "metadata": {},
   "source": [
    "Создайте строку, которая будет оформлена как системное сообщение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd75ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Translate the following into {language}:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf6f13",
   "metadata": {},
   "source": [
    "Теперь вы можете создать шаблон промпта.\n",
    "Он будет состоять из комбинации `system_template` и шаблона для ввода текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88e566f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9711ba6",
   "metadata": {},
   "source": [
    "Входными данными для этого шаблона является словарь.\n",
    "Вы можем поэкспериментировать с этим шаблоном, чтобы увидеть, что он делает сам по себе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f781b3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian:'), HumanMessage(content='hi')])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49ba9e",
   "metadata": {},
   "source": [
    "Шаблон возвращает объект `ChatPromptValue`, который состоит из двух сообщений.\n",
    "Вы можете получить доступ к напрямую сообщениямм с помощью метода `.to_messages()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2159b619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into italian:'),\n",
       " HumanMessage(content='hi')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4267a8",
   "metadata": {},
   "source": [
    "Теперь объедините все три компонента вместе: шаблон, модель и парсер вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c6beb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e45595a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ciao'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b19cecb",
   "metadata": {},
   "source": [
    "<!--\n",
    "Если мы посмотрим на трассировку LangSmith, мы увидим все три компонента в [трассировке LangSmith](https://smith.langchain.com/public/bc49bec0-6b13-4726-967f-dbd3448b786d/r).\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a515ddd0",
   "metadata": {},
   "source": [
    "## Развертывание с LangServe\n",
    "\n",
    "GigaServe помогает развертывать цепочки GigaChain в виде REST API.\n",
    "Использовать GigaServe для работы с GigaChain необязательно.\n",
    "Тем не менее ниже приводится пример, как вы можете развернуть приложение с помощью GigaServe.\n",
    "\n",
    "Пример использует Python-файл, работа с которым вполняется с помощью командной строки.\n",
    "\n",
    "Установка GigaServe:\n",
    "```bash\n",
    "pip install \"langserve[all]\"\n",
    "```\n",
    "\n",
    "### Сервер\n",
    "\n",
    "Для создания сервера для приложения, создайте файл `serve.py`.\n",
    "Файл будет содеражать логику для развертывания приложения.\n",
    "Файл состоит из трех частей:\n",
    "\n",
    "1. Определение цепочки, которую вы создали выше.\n",
    "2. Приложение FastAPI.\n",
    "3. Определение пути для доступа к цепочкие с помощью `langserve.add_routes`.\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "from typing import List\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langserve import add_routes\n",
    "\n",
    "# 1. Создание шаблона промпта\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "# 2. Создание модели\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# 3. Создание парсера\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 4. Создание цепочки\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "# 4. Определение приложения\n",
    "app = FastAPI(\n",
    "  title=\"GigaChain Server\",\n",
    "  version=\"1.0\",\n",
    "  description=\"Простой сервер API, использующий Runnable-интерфейсы GigaChain.\",\n",
    ")\n",
    "\n",
    "# 5. Добавление пути цепочки\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    chain,\n",
    "    path=\"/chain\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)\n",
    "```\n",
    "\n",
    "Запустите файл:\n",
    "```bash\n",
    "python serve.py\n",
    "```\n",
    "Вы должны увидеть, что ваша цепочка доступна по адресу [http://localhost:8000](http://localhost:8000).\n",
    "\n",
    "### Песочница\n",
    "\n",
    "Приложения GigaServe предоставляют доступ к простому [пользовательскому интерфейсу](https://github.com/langchain-ai/langserve/blob/main/README.md#playground) для настройки и вызова приложения с потоковым выводом и отображением промежуточных шагов.\n",
    "Вы можете попробовать его по адресу [http://localhost:8000/chain/playground/](http://localhost:8000/chain/playground/).\n",
    "Введите такие же входные данные, как и раньше — `{\"language\": \"italian\", \"text\": \"hi\"}` — приложение должно ответить так же, как и раньше.\n",
    "\n",
    "### Клиент\n",
    "\n",
    "Для настройки клиентской части используйте `[langserve.RemoteRunnable](/docs/langserve/#client)`.\n",
    "Так вы сможете взаимодействовать с доступной цепочкой так, как если бы она выполнялась на стороне клиента.\n",
    "\n",
    "```python\n",
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/chain/\")\n",
    "remote_chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "```\n",
    "\n",
    "<CodeOutputBlock lang=\"python\">\n",
    "\n",
    "```python\n",
    "    'Ciao'\n",
    "```\n",
    "\n",
    "</CodeOutputBlock>\n",
    "\n",
    "Подробнее — в [документации GigaServe](/docs/langserve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85174643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/chain/\")\n",
    "remote_chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b78a9",
   "metadata": {},
   "source": [
    "To learn more about the many other features of LangServe [head here](/docs/langserve)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befdb168",
   "metadata": {},
   "source": [
    "## Смотрите также\n",
    "\n",
    "Чтобы глубже погрузиться в разработку приложений с помощью GigaChain, ознакомьтесь с разделами:\n",
    "\n",
    "- [Обучающие материалы](/docs/tutorials);\n",
    "- [Руководства](/docs/how_to);\n",
    "- [Основные понятия](/docs/concepts)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
